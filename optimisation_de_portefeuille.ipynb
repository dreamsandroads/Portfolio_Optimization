{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "L8JZp4XrqlXO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxopt import blas, solvers\n",
    "import pandas as pd\n",
    "import cvxopt\n",
    "import math as m\n",
    "from math import log10, sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Modélisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lpcZ6v-4qlXP",
    "outputId": "6d159211-14d3-4cc2-f0eb-378bce6726be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nombre d'actifs :\n",
    "n_assets = 5\n",
    "\n",
    "# Nombre d'observations (nbr de jours) : \n",
    "n_obs = 1260 # 5 ans, 1 année = (environ) 252 jours.\n",
    "\n",
    "# On génère les rendements journaliers de nos 5 actifs : on choisit de les simuler à l'aide \n",
    "# d'une loi normale centrée réduite, en effet les rendements fictifs ainsi obtenus sont proches des résultats empiriques \n",
    "# (cours des actions).\n",
    "# On ajoute des tendances décidées de manière aléatoire (de même, les durées de ces tendances sont décidées de manière \n",
    "# aléatoire pour chaque actif) : \n",
    "def  Init_rendement(temps1, temps2, moymin, moymax, n_assets = 5, n_obs = 1260):\n",
    "    return_vec = np.random.randn(n_assets, n_obs) \n",
    "    for p in range(n_assets): \n",
    "        cpt = 0 \n",
    "        while cpt < n_obs : \n",
    "            duree_tendance = np.random.randint(temps1,temps2+1)\n",
    "            tendance = np.random.uniform(moymin, moymax)\n",
    "            return_vec[p,cpt:duree_tendance+cpt] = (return_vec[p,cpt:duree_tendance+cpt] + tendance)/30\n",
    "            cpt += duree_tendance\n",
    "    return(return_vec[:,:n_obs])\n",
    "\n",
    "return_vec = Init_rendement(159,250,-0.05,0.05)\n",
    "# print(return_vec)\n",
    "\n",
    "\n",
    "# Le test vérifie la taille du tableau renvoyé et que les rendements sont compris entre -1 et 1.  \n",
    "\n",
    "def testunitaire1():\n",
    "  if Init_rendement(40,200,-0.005,0.01).shape != (5,1260):\n",
    "    return False\n",
    "  else : \n",
    "    for i in range (5):\n",
    "      for j in range(1260):\n",
    "        m = Init_rendement(40, 200, -0.005, 0.01)[i][j]\n",
    "        if (m < -1) or (m > 1): \n",
    "          return False\n",
    "  return True \n",
    "\n",
    "testunitaire1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4f98JpF4qlXQ"
   },
   "outputs": [],
   "source": [
    "# Modélisation des prix des actifs : \n",
    "\n",
    "def prix_actif(return_vec, n_assets = 5, n_obs = 1260, prix_init = False):\n",
    "    \n",
    "    return_vec_1 = pd.DataFrame(return_vec).T\n",
    "    prix = pd.DataFrame(columns = ['Action' + str(i) for i in range(1,n_assets+1)])\n",
    "    \n",
    "    if prix_init == False : \n",
    "        prix.loc[0] = [(i+1) * 50 for i in range(n_assets)] # Prix initiaux des 5 actions : (totalement arbitraires) 50, 100, 150, 200, 250\n",
    "    else:\n",
    "        prix.loc[0] = prix_init # Prix initiaux décidés par l'utilisateur. \n",
    "    prix = prix.astype(np.float64)\n",
    "\n",
    "    return_vec_1.columns = ['Action' + str(j) for j in range(1,n_assets+1)]\n",
    "    for i in range(0,n_obs):\n",
    "        prix.loc[i+1] = prix.iloc[i,:] + prix.iloc[i,:]*return_vec_1.iloc[i,:]\n",
    "    # prix.plot(figsize = (15,7))\n",
    "    \n",
    "    return(prix) \n",
    "\n",
    "# prix_actif(Init_rendement(159,250,-0.05,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Méthode de Markowitz et résolution du problème d'optimisation quadratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EfRa3JREqlXQ",
    "outputId": "ff134599-31e1-48c9-bb48-fadd2f85751d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le modèle de Markowitz permet, à partir d’une série de portefeuilles, de répondre à la question : \n",
    "# Comment minimiser mon risque, pour un niveau de rendement minimum souhaité.\n",
    "\n",
    "# Fonction permettant de générer des poids de manière aléatoire, dont la somme vaut 1. \n",
    "# (tous positifs, on ne peut pas vendre à découvert)\n",
    "def poids_aleatoire(n):\n",
    "    \n",
    "    k = np.random.rand(n)\n",
    "    return k / sum(k)\n",
    "\n",
    "# Fonction revoyant la variance moyenne et le rendement moyen d'un portefeuille composé de nos 5 actifs. \n",
    "def port_aleatoire(returns):    \n",
    "\n",
    "    p = np.asmatrix(np.mean(returns, axis=1))\n",
    "    w = np.asmatrix(poids_aleatoire(returns.shape[0]))\n",
    "    C = np.asmatrix(np.cov(returns))\n",
    "    \n",
    "    mu = w * p.T # rendement moyen du portefeuille. \n",
    "    sigma = np.sqrt(w * C * w.T) # risque moyen du portefeuille.\n",
    "    \n",
    "    return mu, sigma\n",
    "\n",
    "# Fonction générant des portefeuilles aléatoires, définis par leur variance et rendement moyen : \n",
    "def generer_port(returnbis, n_portfolios=500):\n",
    "    \n",
    "    means, stds = np.column_stack([port_aleatoire(returnbis) for _ in range(n_portfolios)])\n",
    "    \n",
    "    return means, stds\n",
    "\n",
    "# On représente le nuage de points obtenu (pour chaque portefeuille le couple (means, stds)). \n",
    "def plot_port(returnbis, n_portfolios=500):\n",
    "    means, stds = generer_port(returnbis,n_portfolios)\n",
    "    # fig = plt.figure()\n",
    "    # plt.plot(stds, means, 'o', markersize=5)\n",
    "    # plt.title(\"Représentation graphique des portefeuilles du marché\")\n",
    "    # plt.ylabel('Rendement espéré')\n",
    "    # plt.xlabel('Volatilité')\n",
    "    return(means)\n",
    "\n",
    "\n",
    "means = plot_port(Init_rendement(159,250,-0.05,0.05), n_portfolios=500)\n",
    "\n",
    "# Le test vérifie qu'on a la moyenne sur les 500 portefeuilles et que ces \n",
    "# moyennes sont comprises entre -1 et 1 \n",
    "\n",
    "def testunitaire2():\n",
    "  if len(means) != 500:\n",
    "    return False\n",
    "  else : \n",
    "    for i in range (500):\n",
    "      m = means[i]\n",
    "      if (m < -1) or (m > 1): \n",
    "        return False\n",
    "  return True \n",
    "testunitaire2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ptrgzHjDqlXR"
   },
   "outputs": [],
   "source": [
    "# Résolution du problème d'optimisation : \n",
    "# Objectif : minimiser le risque (càd la variance moyenne) du portefeuille d'actifs \n",
    "# sous contrainte d'un rendement moyen minimum. \n",
    "# Il s'agit d'un problème d'optimisation quadratique : on utilise le package cvxopt pour le résoudre : \n",
    "def cvxopt_qp_solver(r, r_e, cov):\n",
    "    n = len(r)\n",
    "    r = cvxopt.matrix(r)\n",
    "    P = cvxopt.matrix(2.0 * np.array(cov))\n",
    "    q = cvxopt.matrix(np.zeros((n, 1)))\n",
    "    G = cvxopt.matrix(np.concatenate((-np.transpose(r), -np.identity(n)), 0))\n",
    "    h = cvxopt.matrix(np.concatenate((-np.ones((1,1)) * r_e, np.zeros((n,1))), 0))\n",
    "    A = cvxopt.matrix(1.0, (1, n))\n",
    "    b = cvxopt.matrix(1.0)    \n",
    "    return cvxopt.solvers.qp(P, q, G, h, A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Réalisation de backtests pour trouver le pas optimal  de réoptimisation du portefeuille (de réévaluation des poids optimaux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UELT056uqlXR",
    "outputId": "fb4e6189-a772-4d3d-dec5-eb8f1604532e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8513.59450818, 3599.87196363, 2380.0799548 , 1326.78975948,\n",
       "       1203.27861337, 1552.99707448, 1073.36242727, 1222.10146463,\n",
       "       1342.25334256, 1013.81790771, 1164.26977566,  762.93324732])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Objectif du backtest : trouver la durée optimale pour modifier les poids du portefeuille : \n",
    "# Générer les durées à tester : 15-30-45-60-...-180. \n",
    "\n",
    "duree_test = np.array(range(15,181,15))\n",
    "\n",
    "# Fonction pour réaliser un backtest : trouver le pas optimal pour une série financière donnée par l'utilisateur \n",
    "# ou générée de manière aléatoire. \n",
    "\n",
    "def backtesting(duree_test, n_assets, n_obs, dataset = False, data = 0, prix_init = False):\n",
    "    \n",
    "    if dataset != True : \n",
    "        # Création des données : choix des tendances, ... \n",
    "        t1 = np.random.randint(10,20)\n",
    "        t2 = np.random.randint(t1,t1+10)\n",
    "        tt1 = np.random.uniform(-0.005,0.005)\n",
    "        tt2 = np.random.uniform(-0.005,0.005)\n",
    "        return_vec = Init_rendement(t1,t2,min(tt1,tt2),max(tt1,tt2))\n",
    "    else : \n",
    "        return_vec = data # Données fournies par l'utilisateur. \n",
    "            \n",
    "    # Choix du rendement moyen minimum souhaité : 3ème quartile, utilisation de la théorie de Markowitz. \n",
    "    Q3 = round(np.percentile(plot_port(return_vec), 75),5)\n",
    "    \n",
    "    # Calcul des prix des actifs : \n",
    "    prix = prix_actif(return_vec, n_assets, n_obs, prix_init)\n",
    "    return_vec_1 = pd.DataFrame(return_vec).T\n",
    "   \n",
    "    # On cherche les poids optimaux en optimisant sur :\n",
    "    # Ex : pour le 1er pas (i.e. 15) : on optimise sur 0-14, 15-29, 30-44, ...\n",
    "    resultat = np.zeros(len(duree_test))\n",
    "    \n",
    "    for j in range(len(duree_test)):\n",
    "        w=1000 # Richesse initiale de l'agent. \n",
    "        poids = pd.DataFrame(columns = ['Poids' + str(i) for i in range(1,n_assets+1)])\n",
    "\n",
    "        for i in range(0,n_obs,duree_test[j]):\n",
    "            r = return_vec_1.iloc[i:np.minimum(i+duree_test[j],n_obs)].mean().values # Rendement espéré.\n",
    "            r_e = Q3  # Rendement minimum souhaité. \n",
    "            cov = return_vec_1.iloc[i:np.minimum(i+duree_test[j],n_obs)].cov() # matrice de covariance.\n",
    "            \n",
    "            # Résolution du problème d'optimisation sous contrainte : on réduit la précision, des solutions approchées conviennent.\n",
    "            solvers.options['feastol'] = 1e-1\n",
    "            solvers.options['abstol'] = 1e-1\n",
    "            solvers.options['reltol'] = 1e-1\n",
    "            solvers.options['show_progress'] = False\n",
    "            sol = cvxopt_qp_solver(r, r_e, cov)\n",
    "            poids.loc[i]= sol['x']\n",
    "        \n",
    "        \n",
    "        # Evaluation de la richesse finale de l'agent à la fin de la stratégie : journée n_obs[-1]. \n",
    "        argent3 = pd.DataFrame(columns = ['Argent'])\n",
    "        argent3.loc[0] = w\n",
    "        argent3 = argent3.astype(np.float64)\n",
    "        for i in range(0,n_obs,duree_test[j]):\n",
    "            w = w*poids.loc[i].values/prix.iloc[i].values\n",
    "            w = (w*prix.iloc[np.minimum(i+duree_test[j]-1,n_obs-1)]).sum()\n",
    "            argent3.loc[np.minimum(i+duree_test[j],n_obs-1)] = w\n",
    "        # print(argent3)\n",
    "\n",
    "        resultat[j] = argent3.iloc[-1] # Richesse finale de l'agent pour le pas j.  \n",
    "\n",
    "    return(resultat)\n",
    "\n",
    "backtesting(duree_test, 5, 1260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgDWbnpaqlXS",
    "outputId": "0293ca45-233f-4141-a688-fa9815d8e332",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat pour chaque pas (le meilleur pas est celui avec le plus grand score) : \n",
      " \n",
      "                Score obtenu\n",
      "Pas opt = 15          110.0\n",
      "Pas opt = 30           99.0\n",
      "Pas opt = 45           90.0\n",
      "Pas opt = 60           74.0\n",
      "Pas opt = 75           57.0\n",
      "Pas opt = 90           61.0\n",
      "Pas opt = 105          33.0\n",
      "Pas opt = 120          33.0\n",
      "Pas opt = 135          36.0\n",
      "Pas opt = 150          21.0\n",
      "Pas opt = 165          32.0\n",
      "Pas opt = 180          14.0 \n",
      " \n",
      " Le pas optimal est :  15\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Quel est le meilleur pas ? \n",
    "\n",
    "# On fait tourner un grand nombre de fois la fonction backtesting en utilisant différentes séries financières. \n",
    "# On choisit de le faire 10 fois dans le but de trouver le pas qui a permis de réaliser le plus de \"bénéfices\" en moyenne. \n",
    "# On réalise un classement à chaque étape : \n",
    "\n",
    "def trouver_pas_opt(nbr_simul, duree_test, testunit): \n",
    "    n = len(duree_test)\n",
    "    result = np.zeros(n*nbr_simul).reshape((nbr_simul,n))\n",
    "    for i in range(nbr_simul):\n",
    "        indice_classe = np.argsort(backtesting(duree_test,5, 1260),axis=None)\n",
    "        for j in range(n):\n",
    "            result[i,indice_classe[j]] = j \n",
    "    result_condense = np.sum(result, axis=0)\n",
    "    result_condense1 = pd.DataFrame(result_condense, index = [\"Pas opt = \" + str(i) for i in duree_test], columns = [\"Score obtenu\"])\n",
    "    if testunit == False :\n",
    "        print(\"Resultat pour chaque pas (le meilleur pas est celui avec le plus grand score) :\", \"\\n\", \"\\n\", result_condense1, \"\\n\", \"\\n\", \"Le pas optimal est : \", duree_test[np.argmax(result_condense)])\n",
    "    else : \n",
    "        return (duree_test[np.argmax(result_condense)]) #On renvoie uniquement le pas optimal. \n",
    "\n",
    "\n",
    "print(trouver_pas_opt(10, duree_test, False))\n",
    "\n",
    "# L'algorithme met un peu de temps (environ 40 secondes).\n",
    "# Le résultat est 15 la plupart du temps. C'est le pas \"optimal\" d'après ces backtests. \n",
    "\n",
    "# Test unitaire : permet de vérifier qu'au moins une fois sur trois on obtient le pas voulu.\n",
    "# Ce test pose problème par sa complexité (à cause de la complexité de trouver_pas_opt). \n",
    "\n",
    "def testunitaire3():\n",
    "  for i in range (3):\n",
    "    m = trouver_pas_opt(10, duree_test, True)\n",
    "    if m == 15:\n",
    "      return True\n",
    "  return False \n",
    "\n",
    "testunitaire3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Extension aux données réelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUvX_5B-qlXT",
    "outputId": "30a73485-d312-4345-f7d3-08488d322c2f"
   },
   "outputs": [],
   "source": [
    "# Importation des données réelles : on récupère les prix des stocks de toutes les companies du SPX500\n",
    "# sur 5 ans (entre 2013.02.08 et 2018.02.07)\n",
    "\n",
    "import pandas as pd\n",
    "stocks_df = pd.read_csv('all_stocks_5yr.csv',index_col=0,parse_dates=True)\n",
    "unique_stocks_names = stocks_df.Name.unique() # on récupère les noms de tous les stocks\n",
    "\n",
    "stocks = unique_stocks_names\n",
    "daily_returns = pd.DataFrame() \n",
    "for n in range(len(stocks)):\n",
    "    stock_df =  stocks_df.loc[stocks_df.Name==stocks[n],:] #on sélectionne toutes les lignes qui renvoient au stock n\n",
    "    stock_daily_return = stock_df[\"close\"].pct_change() # on calcule les rendements quotidiens de ce stock n\n",
    "    daily_returns[stocks[n]] = stock_daily_return \n",
    "    \n",
    "daily_returns = daily_returns.drop(daily_returns.index[0]) # on enlève la première ligne\n",
    "daily_returns = daily_returns.dropna(axis=1) #on enlève tous les actions qui possèdent une valeur NaN\n",
    "\n",
    "daily_returns.head() # on obtient un dataframe de rendements de taille 1258*470 (1258 jours et 470 actifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1uU5MdEqlXT",
    "outputId": "530b1755-3fc2-4017-c18e-c9e2af9c8dbd"
   },
   "outputs": [],
   "source": [
    "# Modèle de Markowitz \n",
    "\n",
    "# On s'intéresse aux 5 actifs suivants : \"AMZN\",\"GOOGL\",\"MTD\",\"AZO\",\"BLK\"\n",
    "daily_returns.index = range(1258)\n",
    "df2 = daily_returns[[\"AMZN\",\"GOOGL\",\"MTD\",\"AZO\",\"BLK\"]].T.values\n",
    "means, stds = generer_port(df2,500)\n",
    "fig = plt.figure()\n",
    "plt.plot(stds, means, 'o', markersize=5)\n",
    "plt.title(\"Représentation graphique des portefeuilles du marché pour les 5 actifs\")\n",
    "plt.ylabel('Rendement espéré')\n",
    "plt.xlabel('Volatilité')\n",
    "\n",
    "# Retourne le portefeuille optimal pour les 5 actifs considérés\n",
    "\n",
    "means = plot_port(df2)\n",
    "r = (pd.DataFrame(df2).T).mean().values # Rendement espéré : 3e quartile\n",
    "r_e = round(np.percentile(means, 75),5)  # Rendement minimum\n",
    "cov = np.cov(df2) # Matrice de covariance\n",
    "\n",
    "solvers.options['feastol'] = 1e-2\n",
    "solvers.options['abstol'] = 1e-2\n",
    "solvers.options['reltol'] = 1e-2\n",
    "solvers.options['show_progress'] = False\n",
    "sol = cvxopt_qp_solver(r, r_e, cov)\n",
    "print(\"\\n\")\n",
    "x_opt = np.array(sol['x'])\n",
    "print(x_opt,\"\\n\") # Affichage des poids.\n",
    "print(x_opt.sum(),\"\\n\") # On vérifie que la somme des poids vaut 1. \n",
    "print(\"Volatilité (x_opt) :\", np.sqrt(sol[\"primal objective\"])) # Donne le risque minimum. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAitTb-7qlXT",
    "outputId": "1b46c2d7-98ec-499b-9d6f-7e8c03e5bf06"
   },
   "outputs": [],
   "source": [
    "# Backtest avec les données réelles : \n",
    "\n",
    "resultat = pd.DataFrame(backtesting(duree_test, df2.shape[0], df2.shape[1], True, df2, [261.95,393.0777,221.15,385.89,238.16]), index = [\"Pas opt = \" + str(i) for i in duree_test], columns = [\"Somme finale\"])\n",
    "\n",
    "prix_actif(df2, n_assets = df2.shape[0], n_obs = df2.shape[1], prix_init = [261.95,393.0777,221.15,385.89,238.16]).plot(figsize = (15,7))\n",
    "plt.legend([\"AMZN\",\"GOOGL\",\"MTD\",\"AZO\",\"BLK\"])\n",
    "plt.title(\"Evolution des prix des 5 actions\")\n",
    "plt.ylabel(\"Prix\")\n",
    "plt.xlabel('Jour entre le 2013-02-11 et le 2018-02-07')\n",
    "\n",
    "resultat.plot(figsize = (10,5),kind = 'bar')\n",
    "plt.title(\"Représentation de la richesse finale de l'agent pour les différents pas\")\n",
    "plt.ylabel(\"Richesse finale de l'agent\")\n",
    "plt.xlabel('Les pas')\n",
    "print(\"On observe bien que la meilleure stratégie est le pas de 15.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-TvyiBhqlXU"
   },
   "source": [
    "# V. Estimation de la matrice de covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de covariance empirique\n",
    "\n",
    "def sample_cov_matrix(data):\n",
    "    T = len(data)\n",
    "    mean_vector = np.vstack(data.mean().to_numpy())\n",
    "    cov = 0\n",
    "    for i in range(T):\n",
    "        vector = np.vstack(data.iloc[i,:].to_numpy())\n",
    "        cov += np.dot(vector - mean_vector, np.transpose(vector - mean_vector))\n",
    "    cov /= T-1\n",
    "    return cov\n",
    "\n",
    "# Matrice de corrélation déterminée à partir de la matrice de covariance\n",
    "\n",
    "def corr_matrix(cov):\n",
    "    N = len(cov)\n",
    "    corr = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            corr[i,j] = cov[i,j]/sqrt(cov[i,i]*cov[j,j])\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImY58nsOqlXU"
   },
   "source": [
    "### Shrinkage linéaire\n",
    "On écrit la matrice de covariance (sample covariance matrix) dans sa décomposition en valeurs propres : \n",
    "    $$ \\Sigma = \\sum_{i=1}^N \\lambda_i u_i u_i^T$$ où $\\lambda_i$ est la i-ème valeur propre de $\\Sigma$ et $u_i$ son vecteur propre associé.\n",
    "    La matrice réduite (linear shrinkage estimator) est donnée par : \n",
    "    $$ \\hat{\\Sigma} = \\sum_{i=1}^N \\gamma_i u_i u_i^T$$ où $\\gamma_i = \\rho \\lambda_i + (1-\\rho)\\bar{\\lambda}$ où $\\bar{\\lambda}$ est la moyenne des valeurs propres de $\\Sigma$ et $0 < \\rho < 1$, un paramètre qui détermine le degré de réduction. D'où :\n",
    "    $$ \\hat{\\Sigma} = (1-\\rho) \\Sigma + \\rho \\bar{\\lambda} I_N$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-VALrs2qlXV"
   },
   "outputs": [],
   "source": [
    "def shrink_cov(data, rho):\n",
    "    cov = sample_cov_matrix(data)\n",
    "    N = cov.shape[0]\n",
    "    m = np.mean(np.linalg.eigh(cov)[0])\n",
    "    target = np.identity(N)*m\n",
    "    sigma_shrink = (1-rho)*cov + rho*target\n",
    "    return sigma_shrink\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVk9StVhqlXV"
   },
   "source": [
    "### Random Matrix Theory 0 (RMT-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eECJiOPaqlXV",
    "outputId": "d869de03-3c1f-42d1-e601-9e9d7838fb56"
   },
   "outputs": [],
   "source": [
    "#Répartition des valeurs propres (en log) de la matrice de covariance : \n",
    "def plot_eigenvalues_distribution(data):\n",
    "    cov = sample_cov_matrix(data)\n",
    "    corr = corr_matrix(cov)\n",
    "    eigenvalues = np.linalg.eigh(corr)[0]\n",
    "    \n",
    "    # Echelle en log (log_scale)\n",
    "    log_eigenvalues = [log10(l) for l in eigenvalues]\n",
    "    min_scale = -2\n",
    "    max_scale = 2.2\n",
    "    pas = 0.04\n",
    "    N = int((max_scale-min_scale)/pas + 1)\n",
    "    \n",
    "    log_scale = [min_scale]\n",
    "    for k in range(1,N):\n",
    "        log_scale.append(min_scale+k*pas)\n",
    "    \n",
    "    nb_of_eigenvalues = [0]*N\n",
    "    for k in range(N):\n",
    "        c=0\n",
    "        for l in log_eigenvalues:\n",
    "            if l>-2+k*pas and l<=-2+(k+1)*pas:\n",
    "                c+=1\n",
    "        nb_of_eigenvalues[k]=c\n",
    "        \n",
    "    Q = data.shape[0]/data.shape[1] \n",
    "    lambda_1 = np.max(eigenvalues)\n",
    "    lambda_max = (1-(lambda_1/data.shape[1]))*(1+1/Q+2*np.sqrt(1/Q))\n",
    "    \n",
    "    plt.plot(log_scale,nb_of_eigenvalues)\n",
    "    plt.fill_between(log_scale,nb_of_eigenvalues, color='#539ecd')\n",
    "    plt.axvline(x=log10(lambda_max),color='red')\n",
    "    plt.title('Distribution des valeurs propres pour le jeu de données all_stocks_5yr')\n",
    "    plt.xlabel('Valeurs propres (échelle log)')\n",
    "    plt.ylabel('Densité')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "plot_eigenvalues_distribution(daily_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_aléatoire = pd.DataFrame(np.random.normal(0,1,size=(1258,470)))\n",
    "plt.title('Distribution des valeurs propres pour une matrice aléatoire de taille 1258*470')\n",
    "plot_eigenvalues_distribution(matrice_aléatoire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiOoE5EzqlXV"
   },
   "outputs": [],
   "source": [
    "def RMT_0(data):\n",
    "    \n",
    "    Q = data.shape[0]/data.shape[1] #ratio fixé = T/N\n",
    "    cov = sample_cov_matrix(data)\n",
    "    corr = corr_matrix(cov)\n",
    "    corr_eigenvalues = np.linalg.eigh(corr)[0]\n",
    "    \n",
    "    lambda_1 = np.max(corr_eigenvalues)\n",
    "    lambda_max = (1-(lambda_1/data.shape[1]))*(1+1/Q+2*np.sqrt(1/Q))\n",
    "    \n",
    "    # Diagonalisation de la matrice de corrélation\n",
    "    P = np.linalg.eigh(corr)[1] # matrice de passage\n",
    "    D = np.diag(np.linalg.eigh(corr)[0]) # matrice diagonale de valeurs propres\n",
    "    \n",
    "    # On remplace les valeurs propres (sur la diagonale de D) inférieures ou égales à lambda_max par 0 \n",
    "    D2 = D\n",
    "    for i in range(len(D)):\n",
    "        if D[i][i] <= lambda_max:\n",
    "            D2[i][i] = 0  \n",
    "    H_RMT = P@D2@(P.T)\n",
    "    \n",
    "    # Matrice de corrélation filtrée\n",
    "    C_RMT = H_RMT\n",
    "    for i in range(len(H_RMT)):\n",
    "        C_RMT[i][i] = 1\n",
    "        \n",
    "    # Matrice de covariance filtrée\n",
    "    n = len(C_RMT)\n",
    "    S_RMT = np.zeros((n,n))\n",
    "    for i in range(len(C_RMT)):\n",
    "        for j in range(len(C_RMT)):\n",
    "            S_RMT[i][j] = C_RMT[i][j]*(m.sqrt(cov[i,i]*cov[j,j]))\n",
    "    return S_RMT\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projet_Python_Adrien_Lisa_Edouard-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
